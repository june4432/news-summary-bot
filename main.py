### ğŸ“ main.py
from rss import get_latest_news_urls
from crawler import crawl_news
from fast_news_crawler import crawl_multiple_news  # âœ… ë³‘ë ¬ í¬ë¡¤ë§ í•¨ìˆ˜ë¡œ êµì²´
from summarizer import summarize_news_via_api
from notion_writer import save_to_notion, get_existing_urls_from_notion
from mailer import build_email_body, send_email, get_email_subject
from bulk_mailer import send_bulk_email
from config import (
    api_key, notion_token, notion_database_id,
    sender_email, sender_app_password,
    recipient_email, notion_url
)
import datetime
from log import logger

logger.info("ë‰´ìŠ¤ë ˆí„° ë°œì†¡ ì‘ì—… ì‹œì‘!!")

rss_sources = [
    ("ë§¤ì¼ê²½ì œ - í—¤ë“œë¼ì¸", "https://www.mk.co.kr/rss/30000001/"),
    ("ë§¤ì¼ê²½ì œ - ê²½ì œ", "https://www.mk.co.kr/rss/30100041/"),
    ("ë§¤ì¼ê²½ì œ - êµ­ì œ", "https://www.mk.co.kr/rss/30300018/"),
    ("í•œêµ­ê²½ì œ - ê²½ì œ", "https://www.hankyung.com/feed/economy"),
    ("í•œêµ­ê²½ì œ - êµ­ì œ", "https://www.hankyung.com/feed/international"),
    ("í•œêµ­ê²½ì œ - ì‚¬íšŒ", "https://www.hankyung.com/feed/society"),
]

news_data = []
existing_urls = get_existing_urls_from_notion(notion_token, notion_database_id)

logger.info("ë…¸ì…˜ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")

for category, rss_url in rss_sources:
    urls = get_latest_news_urls(rss_url)

    for url in urls:

        logger.info(f"ğŸŒ [{category}] í¬ë¡¤ë§ ì‹œì‘: {url}")

        
        article = crawl_news(url)

        if "Content not found" in article['content'] or article['title'] == "ERROR":
            logger.warning(f"â›” í¬ë¡¤ë§ ì‹¤íŒ¨ë¡œ ì œì™¸ë¨: {article['url']}")
            continue

        logger.info(f"âœ… í¬ë¡¤ë§ ì„±ê³µ: {article['title']}")

        if article['url'] in existing_urls:
            continue  # ì´ë¯¸ ì €ì¥ëœ ë‰´ìŠ¤ëŠ” ìŠ¤í‚µ

        try:
            result = summarize_news_via_api(article['title'], article['content'], api_key)

            # ê²°ê³¼ê°€ íŠœí”Œì´ ì•„ë‹ˆê±°ë‚˜, ê¸¸ì´ê°€ 3ì´ ì•„ë‹ˆë©´ ìŠ¤í‚µ
            if not isinstance(result, tuple) or len(result) != 3:
                logger.warning(f"âš ï¸ ìš”ì•½ í˜•ì‹ ì´ìƒìœ¼ë¡œ ì œì™¸ë¨: {article['url']}, result={result}")
                continue

            summary, tags, emoji = result

            # ìš”ì•½ ì‹¤íŒ¨ì¸ ê²½ìš°ë„ ê±´ë„ˆëœ€
            if summary == "ìš”ì•½ ì‹¤íŒ¨":
                logger.warning(f"âš ï¸ ìš”ì•½ ì‹¤íŒ¨ë¡œ ì œì™¸ë¨: {article['url']}")
                continue

        except Exception as e:
            logger.error(f"âŒ ìš”ì•½ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {article['url']} / {str(e)}", exc_info=True)
            continue

        article['summary'] = summary
        article['tags'] = tags
        article['emoji'] = emoji
        source_name, section_name = category.split(" - ")
        article['category'] = section_name  # âœ… "ê²½ì œ", "êµ­ì œ", "ì‚¬íšŒ"ë§Œ ì €ì¥
        article['source'] = source_name     # âœ… "ë§¤ì¼ê²½ì œ", "í•œêµ­ê²½ì œ"

        news_data.append(article)

        logger.info(f"ğŸ¯ ìš”ì•½ ì™„ë£Œ ë° ê¸°ì‚¬ ì¶”ê°€ë¨: {article['url']}")

# âœ… ë…¸ì…˜ ì €ì¥
for article in news_data:
    save_to_notion(article, notion_token, notion_database_id)

# âœ… ë©”ì¼ + í…”ë ˆê·¸ë¨ ë°œì†¡
send_bulk_email(news_data)

logger.info("ë‰´ìŠ¤ë ˆí„° ë°œì†¡ ì‘ì—… ì™„ë£Œ!!!")