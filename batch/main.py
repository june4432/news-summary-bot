### ğŸ“ main.py
import sys
import os
import json
import datetime

# í˜„ì¬ íŒŒì¼(server.py)ì˜ ë””ë ‰í† ë¦¬ (backend)
current_server_dir = os.path.dirname(os.path.abspath(__file__))

# í”„ë¡œì íŠ¸ì˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (news-summary-bot-divide)ë¥¼ sys.pathì— ì¶”ê°€
# ì´ë ‡ê²Œ í•˜ë©´ 'backend'ì™€ 'batch'ë¥¼ ìµœìƒìœ„ íŒ¨í‚¤ì§€ì²˜ëŸ¼ ì„í¬íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
project_root = os.path.abspath(os.path.join(current_server_dir, '..'))
if project_root not in sys.path: # ì¤‘ë³µ ì¶”ê°€ ë°©ì§€
    sys.path.append(project_root)

from batch.util.rss import get_latest_news_urls
from batch.crawler.crawler import crawl_news
from batch.summarizer.summarizer_gpt import summarize_news_via_api, detect_language, translate_english_article
from batch.notion_writer.notion_writer import save_to_notion, get_existing_urls_from_notion
from batch.mailer.mailer import build_email_body, send_email, get_email_subject
from batch.mailer.bulk_mailer_advanced import send_bulk_email
from batch.common.config import (
    api_key, notion_token, notion_database_id,
    sender_email, sender_app_password,
    recipient_email, notion_url, rss_sources_file
)
from batch.util.recipients_manager import load_recipients, load_recipients_telegram
from batch.common.log import logger

logger.info("ë‰´ìŠ¤ë ˆí„° ë°œì†¡ ì‘ì—… ì‹œì‘!!")

def load_rss_sources():
    with open(rss_sources_file, "r", encoding="utf-8") as f:
        all_sources = json.load(f)

    # âœ… ì´ë©”ì¼ + í…”ë ˆê·¸ë¨ ì‚¬ìš©ì ëª¨ë‘ ë¶ˆëŸ¬ì˜¤ê¸°
    recipients_email = load_recipients()
    recipients_telegram = load_recipients_telegram()
    all_recipients = recipients_email + recipients_telegram

    # âœ… ëª¨ë“  ì‚¬ìš©ìì˜ ê´€ì‹¬ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    interested_keys = set()
    for person in all_recipients:
        for key in person.get("categories", []):
            interested_keys.add(key)  # ì˜ˆ: "ë§¤ì¼ê²½ì œ::êµ­ì œ"

    # âœ… ê´€ì‹¬ìˆëŠ” RSSë§Œ í•„í„°ë§
    filtered_sources = []
    for entry in all_sources:
        key = f"{entry['source']}::{entry['category']}"
        if key in interested_keys:
            filtered_sources.append(entry)

    return filtered_sources

news_data = []

logger.info("rss ë¡œë”© ì‹œì‘")
rss_sources = load_rss_sources()
logger.info("rss ë¡œë”© ì™„ë£Œ")


logger.info("ì´í‹€ì¹˜ ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹œì‘")
existing_urls = get_existing_urls_from_notion()
logger.info("ì´í‹€ì¹˜ ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")

logger.info("ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì‹œì‘")

for item in rss_sources:
    source = item["source"]  # ì˜ˆ: "ë§¤ì¼ê²½ì œ - ê²½ì œ"
    category = item["category"]
    rss_url = item["url"]

    print(f"{source} - {category} - {rss_url}")
    
    urls = get_latest_news_urls(rss_url)

    for url in urls:

        if url in existing_urls:
            continue  # ì´ë¯¸ ì €ì¥ëœ ë‰´ìŠ¤ëŠ” ìŠ¤í‚µ

        logger.info(f"ğŸŒ [{category}] í¬ë¡¤ë§ ì‹œì‘: {url}")

        
        article = crawl_news(url)

        if "Content not found" in article['content'] or article['title'] == "ERROR":
            logger.warning(f"â›” í¬ë¡¤ë§ ì‹¤íŒ¨ë¡œ ì œì™¸ë¨: {article['url']}")
            continue

        logger.info(f"âœ… í¬ë¡¤ë§ ì„±ê³µ: {article['title']}")

        # ğŸŒ ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­ ì²˜ë¦¬
        language = detect_language(article['title'] + " " + article['content'])
        logger.info(f"ğŸ” ì–¸ì–´ ê°ì§€ ê²°ê³¼: {language}")
        logger.info(f"ğŸ” ì›ë³¸ ì œëª©: {article['title'][:100]}...")
        
        # ì›ë³¸ ê¸°ì‚¬ ì •ë³´ ì €ì¥
        article['original_title'] = article['title']
        article['original_content'] = article['content']
        article['language'] = language
        
        logger.info(f"ğŸ” ì›ë³¸ ì •ë³´ ì €ì¥ ì™„ë£Œ - original_title ê¸¸ì´: {len(article.get('original_title', ''))}")
        logger.info(f"ğŸ” ì›ë³¸ ì •ë³´ ì €ì¥ ì™„ë£Œ - original_content ê¸¸ì´: {len(article.get('original_content', ''))}")
        
        # ğŸ”„ ìš”ì•½ ìˆ˜í–‰: ì˜ì–´ ê¸°ì‚¬ëŠ” ì›ë¬¸ìœ¼ë¡œ, í•œêµ­ì–´ ê¸°ì‚¬ëŠ” ê·¸ëŒ€ë¡œ
        try:
            if language == "english":
                logger.info("ğŸŒ ì˜ì–´ ê¸°ì‚¬ - ì›ë¬¸ìœ¼ë¡œ ìš”ì•½ ì‹œì‘ (ê²°ê³¼ëŠ” í•œêµ­ì–´ë¡œ)")
                # ì˜ì–´ ì›ë¬¸ìœ¼ë¡œ ìš”ì•½í•˜ë˜ ê²°ê³¼ëŠ” í•œêµ­ì–´ë¡œ
                result = summarize_news_via_api(article['original_title'], article['original_content'], api_key)
            else:
                logger.info("ğŸ” í•œêµ­ì–´ ê¸°ì‚¬ - ê·¸ëŒ€ë¡œ ìš”ì•½ ì‹œì‘")
                # í•œêµ­ì–´ ê¸°ì‚¬ëŠ” ê·¸ëŒ€ë¡œ ìš”ì•½
                result = summarize_news_via_api(article['title'], article['content'], api_key)

            summary, tags, emoji, is_ad, keyword, mood = result

            # ìš”ì•½ ì‹¤íŒ¨ì¸ ê²½ìš°ë„ ê±´ë„ˆëœ€
            if summary == "ìš”ì•½ ì‹¤íŒ¨":
                logger.warning(f"âš ï¸ ìš”ì•½ ì‹¤íŒ¨ë¡œ ì œì™¸ë¨: {article['url']}")
                continue

        except Exception as e:
            logger.error(f"âŒ ìš”ì•½ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {article['url']} / {str(e)}", exc_info=True)
            continue

        article['category'] = category
        article['source'] = source
        
        article['summary'] = summary
        article['tags'] = tags
        article['emoji'] = emoji
        article['is_ad'] = is_ad
        article['keyword'] = keyword
        article['mood'] = mood
        
        

        news_data.append(article)

        logger.info(f"ğŸ¯ ìš”ì•½ ì™„ë£Œ ë° ê¸°ì‚¬ ì¶”ê°€ë¨: {article['url']}")

logger.info("ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì¢…ë£Œ")

logger.info("ë©”ì¼ ë° í…”ë ˆê·¸ë¨ ë°œì†¡ ì‹œì‘")
# âœ… ë©”ì¼ + í…”ë ˆê·¸ë¨ ë°œì†¡ (ìš”ì•½ëœ ë‚´ìš©ìœ¼ë¡œ ë¨¼ì € ì „ì†¡)
send_bulk_email(news_data)
logger.info("ë©”ì¼ ë° í…”ë ˆê·¸ë¨ ë°œì†¡ ì¢…ë£Œ")

logger.info("ì˜ì–´ ê¸°ì‚¬ ë²ˆì—­ ì‹œì‘")
# ğŸŒ ì˜ì–´ ê¸°ì‚¬ë“¤ë§Œ ë²ˆì—­ ìˆ˜í–‰
for article in news_data:
    if article.get('language') == 'english':
        logger.info(f"ğŸŒ ì˜ì–´ ê¸°ì‚¬ ë²ˆì—­ ì‹œì‘: {article['original_title'][:50]}...")
        try:
            translated_title, translated_content = translate_english_article(
                article['original_title'], article['original_content'], api_key
            )
            article['translated_title'] = translated_title
            article['translated_content'] = translated_content
            
            # ë…¸ì…˜ ì €ì¥ìš©ìœ¼ë¡œ ë²ˆì—­ëœ ë‚´ìš© ì‚¬ìš©
            article['title'] = translated_title
            article['content'] = translated_content
            
            logger.info(f"ğŸŒ ë²ˆì—­ ì™„ë£Œ: {translated_title[:50]}...")
            
        except Exception as e:
            logger.error(f"âŒ ë²ˆì—­ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {article['url']} / {str(e)}", exc_info=True)
            # ë²ˆì—­ ì‹¤íŒ¨ ì‹œì—ë„ ì›ë³¸ìœ¼ë¡œ ë…¸ì…˜ ì €ì¥
            article['translated_title'] = None
            article['translated_content'] = None
            logger.info("âš ï¸ ë²ˆì—­ ì‹¤íŒ¨ - ì›ë³¸ ë‚´ìš©ìœ¼ë¡œ ë…¸ì…˜ ì €ì¥")
    else:
        logger.info(f"ğŸ” í•œêµ­ì–´ ê¸°ì‚¬ - ë²ˆì—­ ê±´ë„ˆëœ€: {article['title'][:50]}...")

logger.info("ì˜ì–´ ê¸°ì‚¬ ë²ˆì—­ ì™„ë£Œ")

logger.info("ë…¸ì…˜ ì €ì¥ ì‹œì‘ (ëª¨ë“  ê¸°ì‚¬ ë©”íƒ€ë°ì´í„°, ì˜ì–´ ê¸°ì‚¬ëŠ” ë³¸ë¬¸ë„)")
# âœ… ë…¸ì…˜ ì €ì¥ (ëª¨ë“  ê¸°ì‚¬ ì €ì¥í•˜ë˜, ì˜ì–´ ê¸°ì‚¬ë§Œ ë³¸ë¬¸ í¬í•¨)
english_articles_saved = 0
korean_articles_saved = 0
for article in news_data:
    save_to_notion(article, notion_token, notion_database_id)
    
    if article.get('language') == 'english':
        english_articles_saved += 1
        logger.info(f"ğŸ“„ ì˜ì–´ ê¸°ì‚¬ ë…¸ì…˜ ì €ì¥ (ë²ˆì—­ë³¸+ì›ë¬¸): {article.get('title', 'Unknown')[:50]}...")
    else:
        korean_articles_saved += 1
        logger.info(f"ğŸ” í•œêµ­ì–´ ê¸°ì‚¬ ë…¸ì…˜ ì €ì¥ (ë©”íƒ€ë°ì´í„°ë§Œ): {article.get('title', 'Unknown')[:50]}...")

logger.info(f"ë…¸ì…˜ ì €ì¥ ì™„ë£Œ - ì˜ì–´ ê¸°ì‚¬ {english_articles_saved}ê°œ (ì „ì²´), í•œêµ­ì–´ ê¸°ì‚¬ {korean_articles_saved}ê°œ (ë©”íƒ€ë§Œ)")

logger.info("ë‰´ìŠ¤ë ˆí„° ë°œì†¡ ì‘ì—… ì™„ë£Œ!!!")